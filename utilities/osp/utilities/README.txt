Notes on OSP (office of sponsored projects) 
Brian Caruso
bdc34@cornell.edu
2005-04-07

This is a set of tools to import data from the OSP datawarehouse into
a vitro system.  This is broken into two parts, the download from OSP
into a local db and the load from the local db into the vitro system.

Steps in doing a download from OSP and import into Vitro:
2) make a db (this only has to be done once)
2) download from the OSP data warehouse to the local db
4) load from the local db to the Vitro system.

The scripts to build the local tables to hold the local OSP data are
found in ./sql.  These scripts are for MySQL 4.1.7 
After setting up a tablespace on your MySQL run osp_table_create.sql
and then osp_index_create.sql.

The download from OSP data warehouse is done by the class
OSPDWDownload.  The parameters are set by a properties file. Currently
the properties are for the two database connections and the drivers
that those connections need.  Usage:
$ ./run.sh OSPDWDownload vivo2_jdbc.properties
The run.sh script is generated by the ant target makeRunSh and it will
execute java with a meaningful classpath containing the jars in the
./lib directory.

The transfer from the local tables to the Vitro system is done by
LocalOsp2Vivo.  The database connections are also set by a properties
file. Usage:
$ ./run.sh LocalOsp2Vivo vivo2_jdbc.properties

Areas for improvement:
The transfer from the remote OSP data warehouse db to a local db is
a hassle.  Replace this with a more direct transfer?  Move the data
from the remote db into xml and then load?  The nice thing about the
current setup is that you can debug the intermediate stage, run
OSPDWDownload, verify what it did, and then run LocalOsp2Vivo.
What about generating SQL and saving it to a file?  Then just
doing a cat ospdata.sql | mysql vivo3?  That might work well.

ChangeQueue: There are some tools to do a ChangeQueue where the
changes are placed in a queue for human review before being executed
on the vitro db.  This needs to be improved.